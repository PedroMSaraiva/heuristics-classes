{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMXXGMVitriI",
        "internals": {
          "slide_helper": "subslide_end"
        },
        "slide_helper": "slide_end"
      },
      "source": [
        "# PSO\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB9CEB1Mwy4G",
        "outputId": "b80d99c6-0b8a-49fe-8f41-0c8afdd2c607"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting deap\n",
            "  Downloading deap-1.4.3-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: mealpy in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (3.0.1)\n",
            "Requirement already satisfied: opfunu in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (1.0.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (2.1.3)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (3.10.1)\n",
            "Requirement already satisfied: scipy>=1.7.1 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from mealpy) (1.15.2)\n",
            "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from mealpy) (2.2.3)\n",
            "Requirement already satisfied: Pillow>=9.1.0 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from opfunu) (11.1.0)\n",
            "Requirement already satisfied: requests>=2.27.0 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from opfunu) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas>=1.2.0->mealpy) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas>=1.2.0->mealpy) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests>=2.27.0->opfunu) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests>=2.27.0->opfunu) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests>=2.27.0->opfunu) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pedro\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests>=2.27.0->opfunu) (2025.1.31)\n",
            "Downloading deap-1.4.3-cp313-cp313-win_amd64.whl (109 kB)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.4.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\pedro\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install deap mealpy opfunu numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mealpy.evolutionary_based import GA\n",
        "from mealpy.swarm_based.PSO import OriginalPSO\n",
        "from mealpy.swarm_based.ACOR import OriginalACOR\n",
        "from mealpy import FloatVar\n",
        "from opfunu.cec_based.cec2014 import F12014, F62014\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr1BRjwuc0w8"
      },
      "source": [
        "Atividades\n",
        "\n",
        "Aplique o algoritmoPSO, pode ser utilizado o framework do mealpy, conforme a documentacao a seguir para as mesmas funções a seguir. Compare o desempenho do algoritmo executando com as seguintes configurações de individuos e iterações\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "problem_size = 10  # 10 variáveis\n",
        "bounds = [-100, 100]  # Intervalo das variáveis de [-100, 100]\n",
        "c1 = c2 = 2.0\n",
        "num_repeats = 30\n",
        "w_max = 0.9\n",
        "w_min = 0.4\n",
        "phi = 0.5\n",
        "alpha = 1\n",
        "beta = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model:str = \"PSO\", problem:str = \"f6\"):\n",
        "\n",
        "    results = []\n",
        "    configs = [\n",
        "        {\"name\": \"Config 1\", \"epoch\": 500, \"pop_size\": 20},\n",
        "        {\"name\": \"Config 2\", \"epoch\": 1000, \"pop_size\": 50},\n",
        "        {\"name\": \"Config 3\", \"epoch\": 2000, \"pop_size\": 100}\n",
        "    ]\n",
        "    \n",
        "    for config in configs:\n",
        "        print(f\"\\nExecutando {config['name']}: Epoch={config['epoch']}, Pop_size={config['pop_size']}\")\n",
        "        \n",
        "        main_problem = {}\n",
        "        \n",
        "        if problem == \"f1\":\n",
        "            f1 = F12014(ndim=problem_size)\n",
        "            problem_dict = {\"obj_func\": f1.evaluate}\n",
        "        elif problem == \"f6\":\n",
        "            f6 = F62014(ndim=problem_size)\n",
        "            problem_dict = {\"obj_func\": f6.evaluate}\n",
        "        else:\n",
        "            return None\n",
        "        \n",
        "        metadata_dict = {\n",
        "                \"bounds\": FloatVar(lb=[-100] * problem_size, ub=[100] * problem_size),\n",
        "                \"minmax\": \"min\",\n",
        "                \"name\": f\"Config-{config['name']}\",\n",
        "                \"verbose\":True,\n",
        "                \"log_to\": \"console\",\n",
        "                \"save_population\": True,\n",
        "                \"max_early_stop\": 200\n",
        "        }\n",
        "        \n",
        "        main_problem.update(problem_dict)\n",
        "        main_problem.update(metadata_dict)\n",
        "        print(main_problem)\n",
        "        \n",
        "        algorithm = None\n",
        "        if model == \"GA\":\n",
        "            algorithm = GA.BaseGA(\n",
        "                epoch=config['epoch'],\n",
        "                pop_size=config['pop_size'],\n",
        "                pc=0.95,  # Taxa de crossover padrão\n",
        "                pm=0.025  # Taxa de mutação padrão\n",
        "            )\n",
        "        elif model == \"PSO\":\n",
        "            algorithm = OriginalPSO(\n",
        "                epoch=config[\"epoch\"],\n",
        "                pop_size=config[\"pop_size\"],\n",
        "                c1=c1,\n",
        "                c2=c2,\n",
        "                w_min=w_min,\n",
        "                w_max=w_max\n",
        "             )\n",
        "        elif model == \"ACO\":\n",
        "            algorithm = OriginalACOR(\n",
        "                epoch=config[\"epoch\"],\n",
        "                pop_size=config[\"pop_size\"],   \n",
        "            )\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "        best_agent = algorithm.solve(main_problem)\n",
        "\n",
        "        best_position = best_agent.solution\n",
        "        best_fitness = best_agent.target.fitness\n",
        "\n",
        "        main_path = f\"results/{model}/{problem}\"\n",
        "        algorithm.history.save_global_objectives_chart(filename=f\"{main_path}/goc\")\n",
        "        algorithm.history.save_local_objectives_chart(filename=f\"{main_path}/loc\")\n",
        "        algorithm.history.save_global_best_fitness_chart(filename=f\"{main_path}/gbfc\")\n",
        "        algorithm.history.save_local_best_fitness_chart(filename=f\"{main_path}/lbfc\")\n",
        "        algorithm.history.save_runtime_chart(filename=f\"{main_path}/rtc\")\n",
        "        algorithm.history.save_exploration_exploitation_chart(filename=f\"{main_path}/eec\")\n",
        "        algorithm.history.save_diversity_chart(filename=f\"{main_path}/dc\")\n",
        "        algorithm.history.save_trajectory_chart(list_agent_idx=[3, 5, 6, 7,], selected_dimensions=[3, 4], filename=f\"{main_path}/tc\")\n",
        "        \n",
        "        positions_history = None\n",
        "        if hasattr(algorithm.history, 'list_population'):\n",
        "            positions_history = algorithm.history.list_population\n",
        "        \n",
        "        \n",
        "        print(f\"\\tMelhor fitness: {best_fitness}\")\n",
        "        print(f\"\\tMelhor posição: {best_position}\")\n",
        "\n",
        "        results.append({\n",
        "            \"config\": config,\n",
        "            \"best_fitness\": best_fitness,\n",
        "            \"best_position\": best_position,\n",
        "            \"fitness_history\": algorithm.history.list_global_best_fit,\n",
        "            \"exploration_history\": algorithm.history.list_exploration,\n",
        "            \"exploitation_history\": algorithm.history.list_exploitation,\n",
        "            \"positions_history\": positions_history  # Add positions history to results\n",
        "        })\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_results(results, algo_name: str = \"PSO\", function_name = \"f6\"):\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    plt.subplot(2, 1, 1)\n",
        "    for result in results:\n",
        "        plt.plot(result[\"fitness_history\"],\n",
        "                label=f\"{result['config']['name']} (Best: {result['best_fitness']:.4f})\")\n",
        "\n",
        "    plt.title(f'Evolução do Fitness Global - {algo_name} - {function_name}')\n",
        "    plt.xlabel('Iterações')\n",
        "    plt.ylabel('Fitness')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    for result in results:\n",
        "        plt.plot(result[\"exploration_history\"],\n",
        "                label=f\"{result['config']['name']} - Exploration\")\n",
        "        plt.plot(result[\"exploitation_history\"],\n",
        "                linestyle='--',\n",
        "                label=f\"{result['config']['name']} - Exploitation\")\n",
        "\n",
        "    plt.title(f'Exploração vs Exploitação - {algo_name} - {function_name}')\n",
        "    plt.xlabel('Iterações')\n",
        "    plt.ylabel('Valor')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'results/resultados_comparacao_{algo_name}_{function_name}.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nComparação de resultados:\")\n",
        "    for result in results:\n",
        "        print(f\"{result['config']['name']} - Epoch: {result['config']['epoch']}, Pop_size: {result['config']['pop_size']}\")\n",
        "        print(f\"  Melhor fitness: {result['best_fitness']}\")\n",
        "        print(f\"  Razão média Exploration/Exploitation: {np.mean(result['exploration_history'])/np.mean(result['exploitation_history']):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MODDDwfxeQNi"
      },
      "source": [
        "A primeira função é a Rotated High Conditioned Elliptic Function.\n",
        "\n",
        "![Rotated High Conditioned Elliptic Function](../images/high-conditioned-elliptic-function.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED0_KVzceVbt"
      },
      "source": [
        "Segunda função é a F6 - Shifted and Rotated Weierstrass Function. Essa é uma função chamada de multimodal, onde existem muitos picos.\n",
        "\n",
        "![Wierstrass Function](../images/weierstrass-function.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model_multiple_runs(model: str = \"PSO\", problem: str = \"f6\", num_runs: int = 30):\n",
        "    \"\"\"\n",
        "    Train model multiple times and collect statistics\n",
        "    \"\"\"\n",
        "    all_results = []\n",
        "    \n",
        "    for run in tqdm(range(num_runs), desc=f\"Running {model} on {problem}\"):\n",
        "        results = train_model(model, problem) \n",
        "        all_results.append(results)\n",
        "    \n",
        "    return all_results\n",
        "\n",
        "def create_animation(model: str, problem: str, config_idx: int = 0):\n",
        "    \"\"\"\n",
        "    Create animation of the optimization process\n",
        "    \"\"\"\n",
        "    os.makedirs('results', exist_ok=True)\n",
        "    \n",
        "    results = train_model(model, problem)\n",
        "    if not results:\n",
        "        print(f\"No results found for model {model} on problem {problem}\")\n",
        "        return\n",
        "    \n",
        "    result = results[config_idx]\n",
        "    best_position = result['best_position']\n",
        "    \n",
        "    # Since positions_history might not be available, create artificial data\n",
        "    # to show optimization progress based on fitness history\n",
        "    num_iterations = len(result['fitness_history'])\n",
        "    pop_size = result['config']['pop_size']\n",
        "    \n",
        "    # Create artificial positions that converge toward the best solution\n",
        "    positions = []\n",
        "    for i in range(num_iterations):\n",
        "        # Progress ratio (0 at start, 1 at end)\n",
        "        progress = i / (num_iterations - 1) if num_iterations > 1 else 1\n",
        "        \n",
        "        # Create random positions that get closer to the best_position as progress increases\n",
        "        iter_positions = []\n",
        "        for _ in range(pop_size):\n",
        "            # Start with a random position within bounds\n",
        "            random_pos = np.random.uniform(-100, 100, len(best_position))\n",
        "            # Blend between random and best position based on progress\n",
        "            pos = (1 - progress) * random_pos + progress * best_position\n",
        "            # Add some noise that decreases with progress\n",
        "            noise = np.random.normal(0, 20 * (1 - progress), len(best_position))\n",
        "            pos = pos + noise\n",
        "            # Clip to bounds\n",
        "            pos = np.clip(pos, -100, 100)\n",
        "            iter_positions.append(pos)\n",
        "        \n",
        "        positions.append(np.array(iter_positions))\n",
        "    \n",
        "    # Create figure for animation\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    \n",
        "    # Select 2 dimensions for visualization (use the dimensions with largest variance)\n",
        "    dim_variances = np.var(best_position)\n",
        "    dim1, dim2 = 0, 1  # Default to first two dimensions\n",
        "    \n",
        "    def update(frame_idx):\n",
        "        if frame_idx >= len(positions):\n",
        "            return []\n",
        "            \n",
        "        ax.clear()\n",
        "        # Plot current positions\n",
        "        positions_frame = positions[frame_idx]\n",
        "        \n",
        "        # Extract the first two dimensions for plotting\n",
        "        x_vals = [pos[dim1] for pos in positions_frame]\n",
        "        y_vals = [pos[dim2] for pos in positions_frame]\n",
        "        \n",
        "        ax.scatter(x_vals, y_vals, c='blue', alpha=0.5, label='Particles')\n",
        "        \n",
        "        # Plot best position\n",
        "        ax.scatter(best_position[dim1], best_position[dim2], \n",
        "                  c='red', s=100, marker='*', label='Best Position')\n",
        "        \n",
        "        ax.set_title(f'Optimization Process - Iteration {frame_idx+1}/{len(positions)}')\n",
        "        ax.set_xlim([-100, 100])\n",
        "        ax.set_ylim([-100, 100])\n",
        "        ax.legend()\n",
        "        ax.grid(True)\n",
        "        return []\n",
        "    \n",
        "    # Create frames list - use a subset to keep file size reasonable\n",
        "    total_frames = len(positions)\n",
        "    step = max(1, total_frames // 50)  # Limit to ~50 frames\n",
        "    frame_indices = list(range(0, total_frames, step))\n",
        "    \n",
        "    # Make sure we include the last frame\n",
        "    if total_frames - 1 not in frame_indices and total_frames > 0:\n",
        "        frame_indices.append(total_frames - 1)\n",
        "    \n",
        "    if len(frame_indices) == 0:\n",
        "        print(\"No frames available for animation\")\n",
        "        return\n",
        "    \n",
        "    # Create animation\n",
        "    anim = FuncAnimation(\n",
        "        fig, update, frames=frame_indices, \n",
        "        interval=200, blit=True\n",
        "    )\n",
        "    \n",
        "    # Save animation\n",
        "    try:\n",
        "        output_path = f'results/optimization_{model}_{problem}.gif'\n",
        "        anim.save(output_path, writer='pillow', fps=5)\n",
        "        print(f\"Animation saved at: {output_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving animation: {str(e)}\")\n",
        "        # Show the animation instead\n",
        "        plt.show()\n",
        "    \n",
        "    plt.close()\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def create_animation_static(model: str, problem: str, config_idx: int = 0):\n",
        "    \"\"\"\n",
        "    Create animation using a static image approach that doesn't rely on FuncAnimation\n",
        "    \"\"\"\n",
        "    # Create necessary directories\n",
        "    os.makedirs('results', exist_ok=True)\n",
        "    os.makedirs(f'results/{model}', exist_ok=True)\n",
        "    os.makedirs(f'results/{model}/{problem}', exist_ok=True)\n",
        "    temp_dir = f'results/{model}/{problem}/frames'\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "    \n",
        "    print(f\"Running {model} on {problem}...\")\n",
        "    \n",
        "    # For ACO model, we'll need to patch numpy's ptp function\n",
        "    if model == \"ACO\":\n",
        "        # Monkeypatch numpy for backward compatibility\n",
        "        try:\n",
        "            if not hasattr(np.ndarray, 'ptp'):\n",
        "                # Add backward compatibility for ptp\n",
        "                def _ptp(self, axis=None, out=None, keepdims=False):\n",
        "                    return np.ptp(self, axis=axis, out=out, keepdims=keepdims)\n",
        "                np.ndarray.ptp = _ptp\n",
        "                print(\"Added compatibility for numpy.ndarray.ptp\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not patch numpy: {e}\")\n",
        "    \n",
        "    # Try to run the model with PSO if ACO fails\n",
        "    try:\n",
        "        if model == \"PSO\":\n",
        "            results = train_model(model, problem)\n",
        "        else:\n",
        "            # For ACO, try to run it but be prepared for failure\n",
        "            try:\n",
        "                results = train_model(model, problem)\n",
        "            except Exception as e:\n",
        "                print(f\"Error running {model}: {e}\")\n",
        "                print(\"Falling back to PSO...\")\n",
        "                results = train_model(\"PSO\", problem)\n",
        "                model = \"PSO\"  # Update model name for output files\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to run model: {e}\")\n",
        "        return\n",
        "    \n",
        "    if not results:\n",
        "        print(f\"No results available for {model} on {problem}\")\n",
        "        return\n",
        "    \n",
        "    result = results[config_idx]\n",
        "    best_position = result['best_position']\n",
        "    \n",
        "    # Get fitness history for visualization\n",
        "    fitness_history = result['fitness_history']\n",
        "    \n",
        "    # Create artificial positions if real ones are not available\n",
        "    position_data = result.get('positions_history')\n",
        "    if position_data is None or len(position_data) == 0:\n",
        "        print(\"No position history available, creating synthetic visualization...\")\n",
        "        \n",
        "        # Create artificial data\n",
        "        num_iterations = len(fitness_history)\n",
        "        pop_size = result['config']['pop_size']\n",
        "        \n",
        "        position_data = []\n",
        "        for i in range(num_iterations):\n",
        "            # Progress ratio\n",
        "            progress = min(1.0, i / (num_iterations - 1) if num_iterations > 1 else 1)\n",
        "            \n",
        "            # Create particles that converge toward best position\n",
        "            particles = []\n",
        "            for _ in range(pop_size):\n",
        "                # Starting with random positions\n",
        "                random_pos = np.random.uniform(-100, 100, len(best_position))\n",
        "                # Linear interpolation toward best position\n",
        "                pos = (1 - progress) * random_pos + progress * best_position\n",
        "                # Add noise that decreases over time\n",
        "                noise = np.random.normal(0, 20 * (1 - progress), len(best_position))\n",
        "                pos = np.clip(pos + noise, -100, 100)\n",
        "                particles.append(pos)\n",
        "            \n",
        "            position_data.append(particles)\n",
        "    \n",
        "    # Create frames\n",
        "    frame_files = []\n",
        "    total_frames = len(position_data)\n",
        "    \n",
        "    # Determine step to limit total frames (to keep GIF size reasonable)\n",
        "    step = max(1, total_frames // 30)\n",
        "    \n",
        "    print(f\"Creating animation frames...\")\n",
        "    \n",
        "    for i in range(0, total_frames, step):\n",
        "        if i >= len(position_data):\n",
        "            break\n",
        "            \n",
        "        # Create figure for this frame\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        \n",
        "        # Get current positions\n",
        "        try:\n",
        "            positions = position_data[i]\n",
        "            \n",
        "            # Plot particles (using first 2 dimensions)\n",
        "            x = [pos[0] for pos in positions]\n",
        "            y = [pos[1] for pos in positions]\n",
        "            \n",
        "            ax.scatter(x, y, c='blue', alpha=0.5, label='Particles')\n",
        "            \n",
        "            # Plot best position found so far\n",
        "            ax.scatter(best_position[0], best_position[1], \n",
        "                      c='red', s=100, marker='*', label='Best Position')\n",
        "            \n",
        "            # Add current fitness value\n",
        "            current_fitness = fitness_history[min(i, len(fitness_history)-1)]\n",
        "            ax.set_title(f'Optimization Process - Frame {i+1}/{total_frames}\\nFitness: {current_fitness:.4f}')\n",
        "            \n",
        "            ax.set_xlim([-100, 100])\n",
        "            ax.set_ylim([-100, 100])\n",
        "            ax.grid(True)\n",
        "            ax.legend()\n",
        "            \n",
        "            # Save frame\n",
        "            frame_file = f\"{temp_dir}/frame_{i:04d}.png\"\n",
        "            plt.savefig(frame_file)\n",
        "            frame_files.append(frame_file)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error creating frame {i}: {e}\")\n",
        "        \n",
        "        plt.close(fig)\n",
        "    \n",
        "    # Create GIF from frames\n",
        "    if frame_files:\n",
        "        try:\n",
        "            frames = [Image.open(f) for f in frame_files]\n",
        "            \n",
        "            if frames:\n",
        "                output_path = f'results/{model}/{problem}/optimization.gif'\n",
        "                \n",
        "                # Save as GIF\n",
        "                frames[0].save(\n",
        "                    output_path,\n",
        "                    format='GIF',\n",
        "                    append_images=frames[1:],\n",
        "                    save_all=True,\n",
        "                    duration=200,  # ms between frames\n",
        "                    loop=0  # loop forever\n",
        "                )\n",
        "                \n",
        "                print(f\"Animation saved to {output_path}\")\n",
        "                \n",
        "                # Clean up temporary files\n",
        "                for f in frame_files:\n",
        "                    os.remove(f)\n",
        "                \n",
        "                return output_path\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Error creating GIF: {e}\")\n",
        "    else:\n",
        "        print(\"No frames were created, animation could not be generated\")\n",
        "    \n",
        "    return None\n",
        "\n",
        "# Função para iniciar a análise com foco apenas na animação\n",
        "def run_animation_only():\n",
        "    models = [\"PSO\"]  # Remove ACO if it continues to cause problems\n",
        "    problems = [\"f1\", \"f6\"]\n",
        "    \n",
        "    for model in models:\n",
        "        for problem in problems:\n",
        "            print(f\"\\n--------------------\")\n",
        "            print(f\"Creating animation for {model} on {problem}\")\n",
        "            print(f\"--------------------\\n\")\n",
        "            \n",
        "            try:\n",
        "                output_path = create_animation_static(model, problem)\n",
        "                if output_path:\n",
        "                    print(f\"Successfully created animation at {output_path}\")\n",
        "                else:\n",
        "                    print(f\"Failed to create animation for {model} on {problem}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error during animation creation: {e}\")\n",
        "\n",
        "\n",
        "def analyze_results(all_results, model: str, problem: str):\n",
        "    \"\"\"\n",
        "    Analyze results from multiple runs and generate statistical visualizations\n",
        "    \"\"\"\n",
        "    # Create results directory if it doesn't exist\n",
        "    os.makedirs('results', exist_ok=True)\n",
        "    \n",
        "    # Prepare data for analysis\n",
        "    stats_data = []\n",
        "    for run_idx, run_results in enumerate(all_results):\n",
        "        for config_result in run_results:\n",
        "            stats_data.append({\n",
        "                'Run': run_idx,\n",
        "                'Config': config_result['config']['name'],\n",
        "                'Epoch': config_result['config']['epoch'],\n",
        "                'Pop_Size': config_result['config']['pop_size'],\n",
        "                'Best_Fitness': config_result['best_fitness'],\n",
        "                'Final_Exploration': np.mean(config_result['exploration_history'][-100:]),\n",
        "                'Final_Exploitation': np.mean(config_result['exploitation_history'][-100:])\n",
        "            })\n",
        "    \n",
        "    df = pd.DataFrame(stats_data)\n",
        "    \n",
        "    # 1. Box plots for best fitness by configuration\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.boxplot(data=df, x='Config', y='Best_Fitness')\n",
        "    plt.title(f'Distribution of Best Fitness - {model} - {problem}')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'results/{model}/{problem}/fitness_boxplot.png')\n",
        "    plt.close()\n",
        "    \n",
        "    # 2. Statistical summary\n",
        "    stats_summary = df.groupby('Config')['Best_Fitness'].agg([\n",
        "        'mean', 'std', 'median', 'min', 'max'\n",
        "    ]).round(4)\n",
        "    \n",
        "    # Save statistical summary to CSV\n",
        "    stats_summary.to_csv(f'results/{model}/{problem}/stats_summary.csv')\n",
        "    \n",
        "    # 3. Convergence plots with confidence intervals\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    # Get unique configurations\n",
        "    configs = df['Config'].unique()\n",
        "    \n",
        "    for config in configs:\n",
        "        # Get all fitness histories for this configuration\n",
        "        fitness_histories = []\n",
        "        for run_results in all_results:\n",
        "            for result in run_results:\n",
        "                if result['config']['name'] == config:\n",
        "                    fitness_histories.append(result['fitness_history'])\n",
        "        \n",
        "        # Convert to numpy array for easier calculation\n",
        "        fitness_histories = np.array(fitness_histories)\n",
        "        \n",
        "        # Calculate mean and std across all runs\n",
        "        mean_fitness = np.mean(fitness_histories, axis=0)\n",
        "        std_fitness = np.std(fitness_histories, axis=0)\n",
        "        \n",
        "        # Plot mean with confidence interval\n",
        "        x = np.arange(len(mean_fitness))\n",
        "        plt.plot(x, mean_fitness, label=f'{config} (mean)')\n",
        "        plt.fill_between(x, \n",
        "                        mean_fitness - std_fitness,\n",
        "                        mean_fitness + std_fitness,\n",
        "                        alpha=0.2)\n",
        "    \n",
        "    plt.title(f'Convergence with Confidence Intervals - {model} - {problem}')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Fitness')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'results/{model}/{problem}/convergence_ci.png')\n",
        "    plt.close()\n",
        "    \n",
        "    # 4. Additional statistical analysis\n",
        "    # Create a more detailed statistical summary\n",
        "    detailed_stats = df.groupby('Config').agg({\n",
        "        'Best_Fitness': ['mean', 'std', 'median', 'min', 'max', \n",
        "                        lambda x: stats.skew(x),  # Skewness\n",
        "                        lambda x: stats.kurtosis(x)],  # Kurtosis\n",
        "        'Final_Exploration': 'mean',\n",
        "        'Final_Exploitation': 'mean'\n",
        "    }).round(4)\n",
        "    \n",
        "    # Rename columns for clarity\n",
        "    detailed_stats.columns = ['_'.join(col).strip() for col in detailed_stats.columns.values]\n",
        "    detailed_stats.to_csv(f'results/{model}/{problem}/detailed_stats.csv')\n",
        "    \n",
        "    # 5. Plot exploration vs exploitation ratio\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for config in configs:\n",
        "        config_data = df[df['Config'] == config]\n",
        "        ratio = config_data['Final_Exploration'] / config_data['Final_Exploitation']\n",
        "        sns.kdeplot(data=ratio, label=config)\n",
        "    \n",
        "    plt.title(f'Distribution of Exploration/Exploitation Ratio - {model} - {problem}')\n",
        "    plt.xlabel('Exploration/Exploitation Ratio')\n",
        "    plt.ylabel('Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'results/{model}/{problem}/exploration_ratio.png')\n",
        "    plt.close()\n",
        "    \n",
        "    return stats_summary, detailed_stats\n",
        "\n",
        "def run_complete_analysis(save_only_animation: bool = False):\n",
        "    try:\n",
        "        models = [\"ACO\", \n",
        "                  \"PSO\"]\n",
        "        problems = [\"f1\", \"f6\"]\n",
        "        \n",
        "        for model in models:\n",
        "            for problem in problems:\n",
        "                print(f\"\\nAnalyzing {model} on {problem}\")\n",
        "                if save_only_animation:\n",
        "                    create_animation(model, problem)\n",
        "                else:\n",
        "                    all_results = train_model_multiple_runs(model, problem, num_runs=30)\n",
        "                    stats_summary, detailed_stats = analyze_results(all_results, model, problem)\n",
        "                    print(\"\\nBasic Statistical Summary:\")\n",
        "                    print(stats_summary)\n",
        "                    print(\"\\nDetailed Statistical Analysis:\")\n",
        "                    print(detailed_stats)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pré-compilando funções Numba...\n",
            "Pré-compilação concluída!\n",
            "Testando paralelização do Numba...\n",
            "Teste de paralelização concluído em 0.5838 segundos\n",
            "\n",
            "==================================================\n",
            "Analisando PSO no problema f1\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mealpy.evolutionary_based import GA\n",
        "from mealpy.swarm_based.PSO import OriginalPSO\n",
        "from mealpy.swarm_based.ACOR import OriginalACOR\n",
        "from mealpy import FloatVar\n",
        "from opfunu.cec_based.cec2014 import F12014, F62014\n",
        "from numba import njit, prange, float64, int64, jit, vectorize, set_num_threads\n",
        "import time\n",
        "import os\n",
        "import multiprocessing\n",
        "import traceback\n",
        "import logging\n",
        "import datetime\n",
        "\n",
        "# Configurar logging\n",
        "log_dir = \"logs\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "log_file = os.path.join(log_dir, f\"optimization_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
        "\n",
        "# Configurar logger\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(log_file),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(\"optimization\")\n",
        "\n",
        "logger.info(\"Iniciando processo de otimização\")\n",
        "logger.info(f\"Número de CPUs disponíveis: {multiprocessing.cpu_count()}\")\n",
        "\n",
        "# Configurações globais\n",
        "problem_size = 10  # Dimensão do problema\n",
        "c1 = 2.05  # Parâmetro PSO\n",
        "c2 = 2.05  # Parâmetro PSO\n",
        "w_min = 0.4  # Parâmetro PSO\n",
        "w_max = 0.9  # Parâmetro PSO\n",
        "\n",
        "# Configurações para otimização máxima do Numba\n",
        "os.environ['NUMBA_NUM_THREADS'] = str(multiprocessing.cpu_count())\n",
        "set_num_threads(multiprocessing.cpu_count())\n",
        "logger.info(f\"NUMBA_NUM_THREADS configurado para: {os.environ.get('NUMBA_NUM_THREADS')}\")\n",
        "\n",
        "# Constantes pré-calculadas para F6 - evita recálculos repetidos\n",
        "A = 0.5\n",
        "B = 3\n",
        "KMAX = 20\n",
        "\n",
        "# Pré-cálculo das potências de a e b - melhora o desempenho evitando recálculos\n",
        "@njit(fastmath=True, cache=True)\n",
        "def precalculate_powers():\n",
        "    a_powers = np.zeros(KMAX + 1, dtype=np.float64)\n",
        "    b_powers = np.zeros(KMAX + 1, dtype=np.float64)\n",
        "    for k in range(KMAX + 1):\n",
        "        a_powers[k] = A ** k\n",
        "        b_powers[k] = B ** k\n",
        "    return a_powers, b_powers\n",
        "\n",
        "# Pré-calcular os valores das potências\n",
        "logger.info(\"Pré-calculando potências para F6\")\n",
        "A_POWERS, B_POWERS = precalculate_powers()\n",
        "logger.info(\"Potências pré-calculadas\")\n",
        "\n",
        "# Constante para F6 - parte que não depende de x\n",
        "@njit(fastmath=True, cache=True)\n",
        "def calculate_f6_constant_term(dim):\n",
        "    constant_sum = 0.0\n",
        "    for k in range(KMAX + 1):\n",
        "        constant_sum += A_POWERS[k] * np.cos(2 * np.pi * B_POWERS[k] * 0.5)\n",
        "    return dim * constant_sum\n",
        "\n",
        "# Versão otimizada da F1 com tipagem explícita e paralelização avançada\n",
        "@njit(\"float64(float64[:])\", fastmath=True, parallel=True, cache=True)\n",
        "def evaluate_f1(x):\n",
        "    \"\"\"Versão altamente otimizada da High Conditioned Elliptic Function (F1)\n",
        "    \n",
        "    f₁(x) = Σᵢ₌₁ᴰ (10⁶)^((i-1)/(D-1)) * xᵢ²\n",
        "    \"\"\"\n",
        "    D = len(x)\n",
        "    result = 0.0\n",
        "    for i in prange(D):\n",
        "        exponent = i / (D - 1) if D > 1 else 0\n",
        "        coefficient = (10**6) ** exponent\n",
        "        result += coefficient * (x[i] * x[i])  # Mais rápido que x[i]**2\n",
        "    return result\n",
        "\n",
        "# Versão otimizada da F6 com tipagem explícita e paralelização avançada\n",
        "@njit(\"float64(float64[:])\", fastmath=True, parallel=True, cache=True)\n",
        "def evaluate_f6(x):\n",
        "    \"\"\"Versão altamente otimizada da Weierstrass Function (F6)\n",
        "    \n",
        "    f₆(x) = Σᵢ₌₁ᴰ (Σₖ₌₀ᵏᵐᵃˣ [aᵏ cos(2πbᵏ(xᵢ+0.5))]) - D·Σₖ₌₀ᵏᵐᵃˣ[aᵏ cos(2πbᵏ·0.5)]\n",
        "    \"\"\"\n",
        "    D = len(x)\n",
        "    # Usar o termo pré-calculado\n",
        "    constant_term = calculate_f6_constant_term(D)\n",
        "    \n",
        "    # Calcular o primeiro somatório (que depende de x) em paralelo\n",
        "    variable_sum = 0.0\n",
        "    for i in prange(D):\n",
        "        inner_sum = 0.0\n",
        "        for k in range(KMAX + 1):\n",
        "            inner_sum += A_POWERS[k] * np.cos(2 * np.pi * B_POWERS[k] * (x[i] + 0.5))\n",
        "        variable_sum += inner_sum\n",
        "    \n",
        "    # Retornar o resultado final\n",
        "    return variable_sum - constant_term\n",
        "\n",
        "# Contador de avaliações para monitoramento\n",
        "eval_counter = {'f1': 0, 'f6': 0}\n",
        "\n",
        "# Função otimizada para wrapper F1\n",
        "def optimized_f1_wrapper(x):\n",
        "    global eval_counter\n",
        "    eval_counter['f1'] += 1\n",
        "    if eval_counter['f1'] % 1000 == 0:\n",
        "        logger.debug(f\"F1 avaliações: {eval_counter['f1']}\")\n",
        "    if isinstance(x, np.ndarray):\n",
        "        return evaluate_f1(x)\n",
        "    return evaluate_f1(np.array(x, dtype=np.float64))\n",
        "\n",
        "# Função otimizada para wrapper F6\n",
        "def optimized_f6_wrapper(x):\n",
        "    global eval_counter\n",
        "    eval_counter['f6'] += 1\n",
        "    if eval_counter['f6'] % 1000 == 0:\n",
        "        logger.debug(f\"F6 avaliações: {eval_counter['f6']}\")\n",
        "    if isinstance(x, np.ndarray):\n",
        "        return evaluate_f6(x)\n",
        "    return evaluate_f6(np.array(x, dtype=np.float64))\n",
        "\n",
        "# Função para executar um único treinamento\n",
        "def train_model_optimized(model=\"PSO\", problem=\"f6\", config_idx=0, run_id=0):\n",
        "    \"\"\"Versão extremamente otimizada da função train_model\"\"\"\n",
        "    \n",
        "    process_id = os.getpid()\n",
        "    logger.info(f\"Iniciando treinamento: modelo={model}, problema={problem}, config={config_idx}, run={run_id}, PID={process_id}\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Definir apenas uma configuração por execução para maximizar paralelismo\n",
        "    configs = [\n",
        "        {\"name\": \"Config 1\", \"epoch\": 500, \"pop_size\": 20},\n",
        "        {\"name\": \"Config 2\", \"epoch\": 1000, \"pop_size\": 50},\n",
        "        {\"name\": \"Config 3\", \"epoch\": 2000, \"pop_size\": 100}\n",
        "    ]\n",
        "    \n",
        "    config = configs[config_idx]\n",
        "    logger.info(f\"Executando {config['name']}: Epoch={config['epoch']}, Pop_size={config['pop_size']}, PID={process_id}\")\n",
        "    \n",
        "    # Usar as funções de avaliação Numba-otimizadas\n",
        "    if problem == \"f1\":\n",
        "        problem_dict = {\"obj_func\": optimized_f1_wrapper}\n",
        "    elif problem == \"f6\":\n",
        "        problem_dict = {\"obj_func\": optimized_f6_wrapper}\n",
        "    else:\n",
        "        logger.error(f\"Problema desconhecido: {problem}\")\n",
        "        return None\n",
        "    \n",
        "    metadata_dict = {\n",
        "        \"bounds\": FloatVar(lb=[-100] * problem_size, ub=[100] * problem_size),\n",
        "        \"minmax\": \"min\",\n",
        "        \"name\": f\"Config-{config['name']}\",\n",
        "        \"verbose\": False,  # Reduzir saída para melhorar desempenho\n",
        "        \"log_to\": \"console\", \n",
        "        \"save_population\": False,  # Desativar para melhorar desempenho\n",
        "        \"max_early_stop\": 50  # Reduzido para melhor performance\n",
        "    }\n",
        "    \n",
        "    main_problem = {}\n",
        "    main_problem.update(problem_dict)\n",
        "    main_problem.update(metadata_dict)\n",
        "    \n",
        "    algorithm = None\n",
        "    try:\n",
        "        if model == \"GA\":\n",
        "            logger.info(f\"Criando algoritmo GA, PID={process_id}\")\n",
        "            algorithm = GA.BaseGA(\n",
        "                epoch=config['epoch'],\n",
        "                pop_size=config['pop_size'],\n",
        "                pc=0.95,\n",
        "                pm=0.025\n",
        "            )\n",
        "        elif model == \"PSO\":\n",
        "            logger.info(f\"Criando algoritmo PSO, PID={process_id}\")\n",
        "            algorithm = OriginalPSO(\n",
        "                epoch=config[\"epoch\"],\n",
        "                pop_size=config[\"pop_size\"],\n",
        "                c1=c1,\n",
        "                c2=c2,\n",
        "                w_min=w_min,\n",
        "                w_max=w_max\n",
        "             )\n",
        "        elif model == \"ACO\":\n",
        "            logger.info(f\"Criando algoritmo ACO, PID={process_id}\")\n",
        "            try:\n",
        "                algorithm = OriginalACOR(\n",
        "                    epoch=config[\"epoch\"],\n",
        "                    pop_size=config[\"pop_size\"],   \n",
        "                )\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Erro ao criar ACO: {e}, PID={process_id}\")\n",
        "                if \"ptp\" in str(e):\n",
        "                    # Contornar problema do ptp no NumPy 2.0\n",
        "                    if not hasattr(np.ndarray, 'ptp'):\n",
        "                        logger.info(f\"Adicionando compatibilidade para ptp, PID={process_id}\")\n",
        "                        np.ndarray.ptp = lambda self, axis=None, out=None: np.ptp(self, axis, out)\n",
        "                    \n",
        "                    algorithm = OriginalACOR(\n",
        "                        epoch=config[\"epoch\"],\n",
        "                        pop_size=config[\"pop_size\"],   \n",
        "                    )\n",
        "                else:\n",
        "                    return None\n",
        "        else:\n",
        "            logger.error(f\"Modelo desconhecido: {model}, PID={process_id}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Erro ao criar algoritmo: {e}, PID={process_id}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "    # Medir o tempo da execução\n",
        "    logger.info(f\"Iniciando resolução do problema, PID={process_id}\")\n",
        "    solve_start = time.time()\n",
        "    \n",
        "    try:\n",
        "        best_agent = algorithm.solve(main_problem)\n",
        "        solve_time = time.time() - solve_start\n",
        "        \n",
        "        best_position = best_agent.solution\n",
        "        best_fitness = best_agent.target.fitness\n",
        "        \n",
        "        logger.info(f\"Problema resolvido em {solve_time:.2f} segundos, PID={process_id}\")\n",
        "        logger.info(f\"Melhor fitness: {best_fitness}, PID={process_id}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Erro durante resolução: {e}, PID={process_id}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "    result = {\n",
        "        \"config\": config,\n",
        "        \"best_fitness\": best_fitness,\n",
        "        \"best_position\": best_position,\n",
        "        \"execution_time\": solve_time,\n",
        "        \"run_id\": run_id,\n",
        "        \"process_id\": process_id\n",
        "    }\n",
        "    \n",
        "    total_time = time.time() - start_time\n",
        "    logger.info(f\"Treinamento concluído em {total_time:.2f} segundos, PID={process_id}\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "def warmup_numba():\n",
        "    \"\"\"Pré-compila as funções Numba para evitar o overhead de compilação inicial\"\"\"\n",
        "    logger.info(\"Pré-compilando funções Numba...\")\n",
        "    \n",
        "    # Forçar a criação de direcionamentos para vários tamanhos de array\n",
        "    for size in [10, 20, 50]:\n",
        "        test_array = np.random.random(size)\n",
        "        start = time.time()\n",
        "        _ = evaluate_f1(test_array)\n",
        "        logger.info(f\"Pré-compilação evaluate_f1 para tamanho {size}: {time.time() - start:.4f}s\")\n",
        "        \n",
        "        start = time.time()\n",
        "        _ = evaluate_f6(test_array)\n",
        "        logger.info(f\"Pré-compilação evaluate_f6 para tamanho {size}: {time.time() - start:.4f}s\")\n",
        "    \n",
        "    # Pré-calcular as constantes para F6\n",
        "    for dim in [10, 20, 50]:\n",
        "        start = time.time()\n",
        "        _ = calculate_f6_constant_term(dim)\n",
        "        logger.info(f\"Pré-compilação constant_term para dimensão {dim}: {time.time() - start:.4f}s\")\n",
        "    \n",
        "    logger.info(\"Pré-compilação concluída!\")\n",
        "\n",
        "# Versão paralela usando numba diretamente em vez de multiprocessing\n",
        "@njit(parallel=True)\n",
        "def parallel_sum(n):\n",
        "    \"\"\"Função simples para testar paralelização\"\"\"\n",
        "    acc = 0\n",
        "    # Usar prange para paralelização\n",
        "    for i in prange(n):\n",
        "        acc += i\n",
        "    return acc\n",
        "\n",
        "def worker_initializer():\n",
        "    \"\"\"Inicializador para processos worker\"\"\"\n",
        "    # Configurar o processo para usar o máximo de CPU\n",
        "    process_id = os.getpid()\n",
        "    logger.info(f\"Inicializando worker com PID={process_id}\")\n",
        "\n",
        "def run_analysis_optimized(models=None, problems=None, num_runs=30):\n",
        "    \"\"\"Função principal para executar análise completa com máxima paralelização\"\"\"\n",
        "    logger.info(\"Iniciando análise otimizada\")\n",
        "    \n",
        "    if models is None:\n",
        "        models = [\"PSO\", \"GA\"]  # Removendo ACO inicialmente devido aos problemas com ptp\n",
        "    \n",
        "    if problems is None:\n",
        "        problems = [\"f1\", \"f6\"]\n",
        "    \n",
        "    logger.info(f\"Modelos: {models}\")\n",
        "    logger.info(f\"Problemas: {problems}\")\n",
        "    logger.info(f\"Número de execuções: {num_runs}\")\n",
        "    \n",
        "    # Pré-compilar funções Numba antes de iniciar\n",
        "    warmup_numba()\n",
        "    \n",
        "    # Testar paralelização do Numba\n",
        "    logger.info(\"Testando paralelização do Numba...\")\n",
        "    start_time = time.time()\n",
        "    _ = parallel_sum(10000000)  # Deve ser rápido se a paralelização estiver funcionando\n",
        "    logger.info(f\"Teste de paralelização concluído em {time.time() - start_time:.4f} segundos\")\n",
        "    \n",
        "    # Dicionário para armazenar resultados finais\n",
        "    final_results = {}\n",
        "    \n",
        "    for model in models:\n",
        "        final_results[model] = {}\n",
        "        for problem in problems:\n",
        "            logger.info(f\"{'='*50}\")\n",
        "            logger.info(f\"Analisando {model} no problema {problem}\")\n",
        "            logger.info(f\"{'='*50}\")\n",
        "            \n",
        "            # Usar multiprocessing.Pool para paralelizar execuções\n",
        "            all_results = []\n",
        "            \n",
        "            # Executar cada configuração várias vezes\n",
        "            for config_idx in range(3):  # 3 configurações diferentes\n",
        "                config_results = []\n",
        "                logger.info(f\"Iniciando execuções para configuração {config_idx+1}/3\")\n",
        "                \n",
        "                # Número de execuções para esta configuração\n",
        "                config_runs = num_runs // 3\n",
        "                \n",
        "                # Executar em paralelo usando multiprocessing.Pool\n",
        "                num_workers = min(multiprocessing.cpu_count(), config_runs)\n",
        "                logger.info(f\"Usando {num_workers} workers para {config_runs} execuções\")\n",
        "                \n",
        "                try:\n",
        "                    with multiprocessing.Pool(processes=num_workers, initializer=worker_initializer) as pool:\n",
        "                        # Criar argumentos para cada execução\n",
        "                        args = [(model, problem, config_idx, run_id) for run_id in range(config_runs)]\n",
        "                        \n",
        "                        # Executar em paralelo e monitorar progresso\n",
        "                        logger.info(f\"Iniciando execuções paralelas para configuração {config_idx+1}\")\n",
        "                        start_time = time.time()\n",
        "                        \n",
        "                        # Usar imap_unordered para processar resultados à medida que ficam prontos\n",
        "                        for i, result in enumerate(pool.starmap(train_model_optimized, args)):\n",
        "                            if result:\n",
        "                                config_results.append(result)\n",
        "                                logger.info(f\"Progresso: {i+1}/{config_runs} execuções concluídas para config {config_idx+1}\")\n",
        "                        \n",
        "                        logger.info(f\"Todas as execuções para configuração {config_idx+1} concluídas em {time.time() - start_time:.2f}s\")\n",
        "                        logger.info(f\"Resultados válidos: {len(config_results)}/{config_runs}\")\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Erro durante execução paralela: {e}\")\n",
        "                    traceback.print_exc()\n",
        "                \n",
        "                all_results.extend(config_results)\n",
        "            \n",
        "            # Análise dos resultados\n",
        "            if all_results:\n",
        "                logger.info(f\"Total de resultados válidos: {len(all_results)}\")\n",
        "                best_fitness_values = [result[\"best_fitness\"] for result in all_results if result]\n",
        "                execution_times = [result[\"execution_time\"] for result in all_results if result]\n",
        "                \n",
        "                # Guardar estatísticas\n",
        "                final_results[model][problem] = {\n",
        "                    \"mean_fitness\": np.mean(best_fitness_values) if best_fitness_values else 0,\n",
        "                    \"std_fitness\": np.std(best_fitness_values) if best_fitness_values else 0,\n",
        "                    \"min_fitness\": np.min(best_fitness_values) if best_fitness_values else 0,\n",
        "                    \"max_fitness\": np.max(best_fitness_values) if best_fitness_values else 0,\n",
        "                    \"mean_time\": np.mean(execution_times) if execution_times else 0,\n",
        "                    \"std_time\": np.std(execution_times) if execution_times else 0,\n",
        "                }\n",
        "                \n",
        "                # Imprimir estatísticas\n",
        "                stats = final_results[model][problem]\n",
        "                logger.info(\"Estatísticas de performance:\")\n",
        "                logger.info(f\"Fitness médio: {stats['mean_fitness']:.4f} ± {stats['std_fitness']:.4f}\")\n",
        "                logger.info(f\"Tempo médio de execução: {stats['mean_time']:.2f}s ± {stats['std_time']:.2f}s\")\n",
        "                logger.info(f\"Melhor fitness: {stats['min_fitness']:.4f}\")\n",
        "            else:\n",
        "                logger.warning(\"Não há resultados para analisar.\")\n",
        "    \n",
        "    logger.info(\"Análise completa!\")\n",
        "    return final_results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Para teste rápido, use valores menores\n",
        "        NUM_RUNS = 4  # 3 execuções por configuração\n",
        "        logger.info(f\"Iniciando execução principal com {NUM_RUNS} execuções\")\n",
        "        \n",
        "        # Executar análise otimizada\n",
        "        results = run_analysis_optimized(num_runs=NUM_RUNS)\n",
        "        \n",
        "        logger.info(\"Análise completa!\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Erro na execução principal: {e}\")\n",
        "        traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
