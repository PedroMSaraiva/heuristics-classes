# Atividade Final ‚Äî Organiza√ß√£o e Avalia√ß√£o de Modelos

![Python](https://img.shields.io/badge/python-3.10%2B-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Status](https://img.shields.io/badge/status-Em%20Desenvolvimento-yellow)

## Estrutura de Pastas

- `data/csv/`: arquivos de dados originais.
- `results/`: resultados num√©ricos (csv) de cada experimento.
    - `results/baseline/`: baseline_results.csv
    - `results/genetic/`: genetic_results.csv
    - `results/comparacoes/`: gr√°ficos de compara√ß√£o entre experimentos
- `plots/`: gr√°ficos gerados, organizados por experimento e tipo.
    - `plots/baseline/`: gr√°ficos do baseline
    - `plots/genetic/`: gr√°ficos do genetic
    - `plots/exploratorio/`: histogramas, matriz de correla√ß√£o, pairplot, nulos
- `src/`: fun√ß√µes utilit√°rias centralizadas (m√©tricas, data loading, plots).

## Como Executar

1. Instale as depend√™ncias:
   ```
   pip install -r requirements.txt
   ```

2. Execute os scripts principais:
   ```bash
   # Baseline
   python baseline_mlr.py
   
   # Algoritmo gen√©tico com par√¢metros padr√£o
   python genetic_mlr.py
   
   # Otimiza√ß√£o de hiperpar√¢metros (NOVO!)
   python genetic_mlr.py --optimize --trials 50
   
   # Script auxiliar para otimiza√ß√£o (recomendado)
   python optimize_hyperparams.py quick    # 30 trials
   python optimize_hyperparams.py full     # 100 trials
   python optimize_hyperparams.py best     # usar melhores par√¢metros salvos
   
   # Compara√ß√£o entre modelos
   python compare_results.py results/baseline/baseline_results.csv results/genetic/genetic_results.csv
   
   # Visualiza√ß√£o explorat√≥ria
   python visualize_dataset.py
   ```

## Algoritmo Gen√©tico para Sele√ß√£o de Vari√°veis

O algoritmo gen√©tico (AG) √© utilizado para selecionar automaticamente o subconjunto de features mais relevante para a regress√£o linear m√∫ltipla. Cada indiv√≠duo da popula√ß√£o √© um vetor bin√°rio, onde cada bit indica se a feature correspondente √© usada (1) ou n√£o (0).

### üß¨ Implementa√ß√£o B√°sica

- **Modelagem do Cromossomo:**
  - Exemplo: `[1, 0, 1, 1]` (usa as features 1, 3 e 4)
- **Fitness (Corrigido):**
  - Calculado com cross-validation apenas no conjunto de treino
  - F√≥rmula: `(R¬≤ + 1/MSE) / 2 √ó penalty_features`
  - **Sem data leakage**: Valida√ß√£o/teste n√£o s√£o usados no fitness
- **Restri√ß√µes:**
  - M√°ximo de 90 features selecionadas
  - Sele√ß√£o por torneio (K=4) no crossover
  - Operadores customizados respeitam restri√ß√µes

### üéØ Otimiza√ß√£o Inteligente de Hiperpar√¢metros (NOVO!)

Implementamos otimiza√ß√£o autom√°tica usando **Optuna** (Bayesian Optimization):

- **Hiperpar√¢metros otimizados:**
  - `num_generations` (50-300)
  - `sol_per_pop` (20-100) 
  - `K_tournament` (2-8)
  - `keep_parents` (2-20)
  - `cv_folds` (3-10)
  - `max_features` (30-150)
  - `feature_penalty` (0.1-0.5)

- **Fun√ß√£o objetivo:** 70% R¬≤ + 30% parcim√¥nia
- **Estrat√©gias:**
  - **Quick**: 30 trials (~30 min)
  - **Full**: 100 trials (~2h)
  - **Best**: usa par√¢metros salvos

### ‚öôÔ∏è Como Usar a Otimiza√ß√£o

```bash
# Otimiza√ß√£o r√°pida
python optimize_hyperparams.py quick

# Otimiza√ß√£o completa  
python optimize_hyperparams.py full

# Usar melhores par√¢metros encontrados
python optimize_hyperparams.py best
```

**Arquivos gerados:**
- `results/best_hyperparameters.json`: melhores par√¢metros
- `results/optuna_study.pkl`: hist√≥rico completo

**Documenta√ß√£o completa:** [HYPERPARAMETER_OPTIMIZATION.md](HYPERPARAMETER_OPTIMIZATION.md)

## M√©tricas Calculadas

- **R¬≤**: Coeficiente de determina√ß√£o.
- **MSE**: Mean Squared Error.
- **MAE**: Mean Absolute Error.
- **Bias**: M√©dia dos res√≠duos, conforme f√≥rmula:
  \[
  Bias = \frac{\sum_{i=1}^n (\hat{y}_i - y_i)}{n}
  \]
- **RMSE**: Root Mean Squared Error.
- **SE**: Standard Error, conforme f√≥rmula:
  \[
  SE = \sqrt{\frac{\sum_{i=1}^n (\hat{y}_i - y_i)^2 - \frac{(\sum_{i=1}^n (\hat{y}_i - y_i))^2}{n}}{n-1}}
  \]

## Visualiza√ß√µes

- Histogramas, matriz de correla√ß√£o, pairplot, contagem de nulos (plots/exploratorio).
- Gr√°ficos de real vs previsto, res√≠duos, histogramas de res√≠duos (plots/baseline, plots/genetic).

## Compara√ß√£o

- Use `compare_results.py` para comparar m√©tricas entre experimentos.
- Gr√°ficos de barras s√£o salvos em `results/comparacoes/`.

## Centraliza√ß√£o de Fun√ß√µes

- Todas as m√©tricas est√£o em `src/metrics.py`.
- Scripts importam `compute_metrics` para garantir consist√™ncia.
- Caminhos de resultados e plots s√£o padronizados.

---

## Observa√ß√µes

- Centralize fun√ß√µes para evitar duplicidade e facilitar manuten√ß√£o.
- Siga a estrutura de pastas para manter o projeto organizado.

# Heuristics Classes ‚Äî Atividade Final

Esta pasta cont√©m a **Parte 1 da atividade final** do curso de Heur√≠stica e Modelagem Multiobjetivo. Nela foi criado um **baseline** de Regress√£o Linear M√∫ltipla (MLR) para os dados fornecidos, sem qualquer pr√©‚Äëprocessamento ou sele√ß√£o de vari√°veis.

---

## 1. Objetivo

- Aplicar um modelo de **Multiple Linear Regression** para prever a vari√°vel alvo (`target`) a partir das features dispon√≠veis (`wl` e `input`) nos dados.
- Gerar m√©tricas de avalia√ß√£o b√°sicas (baseline) que servir√£o de refer√™ncia para compara√ß√µes futuras.

## 2. Metodologia

1. **Carregamento dos dados**
   - `all_data_matlab.csv`: cont√©m colunas `wl`, `inputCalibration`, `targetCalibration`, `inputValidation`, `targetTest`, etc.
   - `all_data_IDRC.csv`: lista de valores de refer√™ncia (ordem de valida√ß√£o).
2. **Prepara√ß√£o dos conjuntos**
   - **Treino (calibra√ß√£o)**: linhas onde `inputCalibration` e `targetCalibration` n√£o s√£o nulos.
   - **Valida√ß√£o**: linhas indicadas pelos IDs do arquivo `all_data_IDRC.csv`. Essa parti√ß√£o usa `inputValidation` vs. refer√™ncia do IDRC.
   - **Teste**: resto dos dados com `inputTest` e `targetTest`.
3. **Ajuste do modelo**
   ```python
   from sklearn.linear_model import LinearRegression
   model = LinearRegression()
   model.fit(X_train, y_train)
   ```
4. **C√°lculo das m√©tricas (baseline)**
   - **MSE** (Mean Squared Error)
   - **MAE** (Mean Absolute Error)
   - **R¬≤** (coeficiente de determina√ß√£o)
5. **Gera√ß√£o de sa√≠da**
   - `baseline_results.csv`: cont√©m as m√©tricas para **valida√ß√£o** e **teste**.

---

## 3. Como executar

```bash
# Instalar depend√™ncias (incluindo scikit-learn)
pip install -r requirements.txt

# Entrar na pasta da atividade final
cd atividade_final

# Rodar o script de baseline
python baseline_mlr.py
```

O script ir√° imprimir no console e salvar em `baseline_results.csv`:

- Valores de MSE, MAE e R¬≤ para os conjuntos de **Valida√ß√£o** e **Teste**.

---

## 4. Resultados do baseline

| Conjunto    |    MSE    |    MAE    |     R¬≤     |
|-------------|-----------|-----------|------------|
| **Valida√ß√£o** | 1.09754   | 0.74191   | ‚Äì0.08798   |
| **Teste**     | 1.35652   | 0.88702   | ‚Äì0.02204   |

> **Observa√ß√£o**: R¬≤ negativo indica que a regress√£o linear simples est√° pior que uma previs√£o da m√©dia dos valores. Esse baseline √© uma linha de base para compara√ß√£o com melhorias futuras.

---

## 5. Pr√≥ximos Passos

1. **Normaliza√ß√£o/Escala** das features (`wl` e `input`).
2. **Engenharia de Features** (intera√ß√µes, polin√¥mios, an√°lise de correla√ß√£o).
3. **Modelos regularizados** (`Ridge`, `Lasso`) para evitar overfitting.
4. **Sele√ß√£o de Vari√°veis** (`SelectKBest`, `RFE`).
5. **Reavalia√ß√£o** das m√©tricas para verificar ganhos em MSE, MAE e R¬≤.

---