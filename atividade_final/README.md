# Atividade Final ‚Äî Organiza√ß√£o e Avalia√ß√£o de Modelos

![Python](https://img.shields.io/badge/python-3.10%2B-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Status](https://img.shields.io/badge/status-Em%20Desenvolvimento-yellow)

## Estrutura de Pastas

- `data/csv/`: arquivos de dados originais.
- `results/`: resultados num√©ricos (csv) de cada experimento.
    - `results/baseline/`: baseline_results.csv
    - `results/genetic/`: genetic_results.csv
    - `results/comparacoes/`: gr√°ficos de compara√ß√£o entre experimentos
- `plots/`: gr√°ficos gerados, organizados por experimento e tipo.
    - `plots/baseline/`: gr√°ficos do baseline
    - `plots/genetic/`: gr√°ficos do genetic
    - `plots/exploratorio/`: histogramas, matriz de correla√ß√£o, pairplot, nulos
- `src/`: fun√ß√µes utilit√°rias centralizadas (m√©tricas, data loading, plots).

## Como Executar

1. Instale as depend√™ncias:
   ```
   pip install -r requirements.txt
   ```

2. Execute os scripts principais:
   ```bash
   # ======== EXECU√á√ïES INDIVIDUAIS ========
   
   # Baseline (execu√ß√£o √∫nica)
   python baseline_mlr.py
   
   # Algoritmo gen√©tico com par√¢metros padr√£o (execu√ß√£o √∫nica)
   python genetic_mlr.py
   
   # Otimiza√ß√£o de hiperpar√¢metros (NOVO!)
   python genetic_mlr.py --optimize --trials 50
   
   # Script auxiliar para otimiza√ß√£o (recomendado)
   python optimize_hyperparams.py quick    # 30 trials
   python optimize_hyperparams.py full     # 100 trials
   python optimize_hyperparams.py best     # usar melhores par√¢metros salvos
   
   # ======== AN√ÅLISE ESTAT√çSTICA (NOVO!) ========
   
   # Execu√ß√£o completa: 30 itera√ß√µes + an√°lise comparativa
   python run_statistical_analysis.py
   
   # Executar apenas 30 itera√ß√µes do Baseline MLR
   python run_statistical_analysis.py --baseline-only
   
   # Executar apenas 30 itera√ß√µes do Genetic MLR (com melhores par√¢metros)
   python run_statistical_analysis.py --genetic-only
   
   # Executar apenas an√°lise dos resultados existentes
   python run_statistical_analysis.py --analysis-only
   
   # Scripts individuais de m√∫ltiplas execu√ß√µes
   python baseline_mlr_multiple_runs.py    # 30 execu√ß√µes do baseline
   python genetic_mlr_multiple_runs.py     # 30 execu√ß√µes do gen√©tico
   python analyze_multiple_runs.py         # an√°lise com boxplots
   
   # ======== OUTROS ========
   
   # Compara√ß√£o entre modelos (execu√ß√£o √∫nica)
   python compare_results.py results/baseline/baseline_results.csv results/genetic/genetic_results.csv
   
   # Visualiza√ß√£o explorat√≥ria
   python visualize_dataset.py
   ```

## Algoritmo Gen√©tico para Sele√ß√£o de Vari√°veis

O algoritmo gen√©tico (AG) √© utilizado para selecionar automaticamente o subconjunto de features mais relevante para a regress√£o linear m√∫ltipla. Cada indiv√≠duo da popula√ß√£o √© um vetor bin√°rio, onde cada bit indica se a feature correspondente √© usada (1) ou n√£o (0).

### üß¨ Implementa√ß√£o B√°sica

- **Modelagem do Cromossomo:**
  - Exemplo: `[1, 0, 1, 1]` (usa as features 1, 3 e 4)
- **Fitness (Corrigido):**
  - Calculado com cross-validation apenas no conjunto de treino
  - F√≥rmula: `(R¬≤ + 1/MSE) / 2 √ó penalty_features`
  - **Sem data leakage**: Valida√ß√£o/teste n√£o s√£o usados no fitness
- **Restri√ß√µes:**
  - M√°ximo de 90 features selecionadas
  - Sele√ß√£o por torneio (K=4) no crossover
  - Operadores customizados respeitam restri√ß√µes

### üéØ Otimiza√ß√£o Inteligente de Hiperpar√¢metros (NOVO!)

Implementamos otimiza√ß√£o autom√°tica usando **Optuna** (Bayesian Optimization):

- **Hiperpar√¢metros otimizados:**
  - `num_generations` (50-300)
  - `sol_per_pop` (20-100) 
  - `K_tournament` (2-8)
  - `keep_parents` (2-20)
  - `cv_folds` (3-10)
  - `max_features` (30-150)
  - `feature_penalty` (0.1-0.5)

- **Fun√ß√£o objetivo:** 70% R¬≤ + 30% parcim√¥nia
- **Estrat√©gias:**
  - **Quick**: 30 trials (~30 min)
  - **Full**: 100 trials (~2h)
  - **Best**: usa par√¢metros salvos

### ‚öôÔ∏è Como Usar a Otimiza√ß√£o

```bash
# Otimiza√ß√£o r√°pida
python optimize_hyperparams.py quick

# Otimiza√ß√£o completa  
python optimize_hyperparams.py full

# Usar melhores par√¢metros encontrados
python optimize_hyperparams.py best
```

**Arquivos gerados:**
- `results/best_hyperparameters.json`: melhores par√¢metros
- `results/optuna_study.pkl`: hist√≥rico completo

**Documenta√ß√£o completa:** [HYPERPARAMETER_OPTIMIZATION.md](HYPERPARAMETER_OPTIMIZATION.md)

## üìä An√°lise Estat√≠stica com M√∫ltiplas Execu√ß√µes (NOVO!)

Para obter resultados estatisticamente robustos, implementamos scripts que executam **30 itera√ß√µes** de cada algoritmo e geram an√°lises comparativas detalhadas.

### Scripts de M√∫ltiplas Execu√ß√µes

1. **`baseline_mlr_multiple_runs.py`**
   - Executa o MLR baseline 30 vezes
   - Salva todas as m√©tricas em formato estruturado
   - Gera estat√≠sticas resumo (m√©dia, desvio, quartis)

2. **`genetic_mlr_multiple_runs.py`**  
   - Executa o algoritmo gen√©tico 30 vezes usando os **melhores par√¢metros** encontrados
   - Inclui an√°lise do n√∫mero de features selecionadas
   - Salva fitness evolution para cada execu√ß√£o

3. **`analyze_multiple_runs.py`**
   - Cria **boxplots comparativos** entre baseline e gen√©tico
   - Gera plots individuais para cada m√©trica (R¬≤, MSE, MAE, etc.)
   - An√°lise espec√≠fica da sele√ß√£o de features (distribui√ß√£o, correla√ß√£o com performance)
   - Tabela de estat√≠sticas descritivas completa

4. **`run_statistical_analysis.py`** (Script Principal)
   - Orquestra toda a an√°lise estat√≠stica
   - Execu√ß√£o inteligente com estimativa de tempo
   - Verifica√ß√£o de pr√©-requisitos
   - Op√ß√µes flex√≠veis (apenas baseline, apenas gen√©tico, apenas an√°lise)

### Como Usar

```bash
# An√°lise completa (RECOMENDADO)
python run_statistical_analysis.py
# ‚è±Ô∏è Tempo estimado: 70-140 minutos

# Execu√ß√µes parciais
python run_statistical_analysis.py --baseline-only  # ~5-10 min
python run_statistical_analysis.py --genetic-only   # ~60-120 min  
python run_statistical_analysis.py --analysis-only  # ~2-5 min
```

### Resultados Gerados

**Estrutura de pastas criada:**
```
results/
‚îú‚îÄ‚îÄ multiple_runs/          # Dados das 30 execu√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ baseline_mlr_30_runs_YYYYMMDD_HHMMSS.csv
‚îÇ   ‚îú‚îÄ‚îÄ baseline_mlr_30_runs_YYYYMMDD_HHMMSS.json
‚îÇ   ‚îú‚îÄ‚îÄ baseline_mlr_summary_stats_YYYYMMDD_HHMMSS.json
‚îÇ   ‚îú‚îÄ‚îÄ genetic_mlr_30_runs_YYYYMMDD_HHMMSS.csv
‚îÇ   ‚îú‚îÄ‚îÄ genetic_mlr_30_runs_YYYYMMDD_HHMMSS.json
‚îÇ   ‚îî‚îÄ‚îÄ genetic_mlr_summary_stats_YYYYMMDD_HHMMSS.json
‚îî‚îÄ‚îÄ analysis_plots/         # Visualiza√ß√µes comparativas
    ‚îú‚îÄ‚îÄ comparison_boxplots_YYYYMMDD_HHMMSS.png
    ‚îú‚îÄ‚îÄ r2_analysis_YYYYMMDD_HHMMSS.png
    ‚îú‚îÄ‚îÄ mse_analysis_YYYYMMDD_HHMMSS.png
    ‚îú‚îÄ‚îÄ features_analysis_YYYYMMDD_HHMMSS.png
    ‚îî‚îÄ‚îÄ statistical_summary_YYYYMMDD_HHMMSS.csv
```

**Tipos de an√°lise:**
- **Boxplots comparativos**: Distribui√ß√£o de todas as m√©tricas
- **Violin plots**: Distribui√ß√£o detalhada das performances  
- **An√°lise de features**: N√∫mero √≥timo, correla√ß√£o com R¬≤
- **Estat√≠sticas descritivas**: M√©dia, desvio, quartis, min/max
- **Teste de signific√¢ncia**: Compara√ß√£o estat√≠stica entre algoritmos

### Vantagens da An√°lise Estat√≠stica

‚úÖ **Base estat√≠stica robusta** (30 execu√ß√µes vs 1 execu√ß√£o)  
‚úÖ **Quantifica√ß√£o da variabilidade** dos algoritmos  
‚úÖ **Compara√ß√£o objetiva** com intervalos de confian√ßa  
‚úÖ **Identifica√ß√£o de outliers** e comportamentos an√¥malos  
‚úÖ **An√°lise de estabilidade** dos algoritmos  
‚úÖ **Visualiza√ß√µes profissionais** para relat√≥rios  

## M√©tricas Calculadas

- **R¬≤**: Coeficiente de determina√ß√£o.
- **MSE**: Mean Squared Error.
- **MAE**: Mean Absolute Error.
- **Bias**: M√©dia dos res√≠duos, conforme f√≥rmula:
  \[
  Bias = \frac{\sum_{i=1}^n (\hat{y}_i - y_i)}{n}
  \]
- **RMSE**: Root Mean Squared Error.
- **SE**: Standard Error, conforme f√≥rmula:
  \[
  SE = \sqrt{\frac{\sum_{i=1}^n (\hat{y}_i - y_i)^2 - \frac{(\sum_{i=1}^n (\hat{y}_i - y_i))^2}{n}}{n-1}}
  \]

## Visualiza√ß√µes

- Histogramas, matriz de correla√ß√£o, pairplot, contagem de nulos (plots/exploratorio).
- Gr√°ficos de real vs previsto, res√≠duos, histogramas de res√≠duos (plots/baseline, plots/genetic).

## Compara√ß√£o

- Use `compare_results.py` para comparar m√©tricas entre experimentos.
- Gr√°ficos de barras s√£o salvos em `results/comparacoes/`.

## Centraliza√ß√£o de Fun√ß√µes

- Todas as m√©tricas est√£o em `src/metrics.py`.
- Scripts importam `compute_metrics` para garantir consist√™ncia.
- Caminhos de resultados e plots s√£o padronizados.

---

## Observa√ß√µes

- Centralize fun√ß√µes para evitar duplicidade e facilitar manuten√ß√£o.
- Siga a estrutura de pastas para manter o projeto organizado.

# Heuristics Classes ‚Äî Atividade Final

Esta pasta cont√©m a **Parte 1 da atividade final** do curso de Heur√≠stica e Modelagem Multiobjetivo. Nela foi criado um **baseline** de Regress√£o Linear M√∫ltipla (MLR) para os dados fornecidos, sem qualquer pr√©‚Äëprocessamento ou sele√ß√£o de vari√°veis.

---

## 1. Objetivo

- Aplicar um modelo de **Multiple Linear Regression** para prever a vari√°vel alvo (`target`) a partir das features dispon√≠veis (`wl` e `input`) nos dados.
- Gerar m√©tricas de avalia√ß√£o b√°sicas (baseline) que servir√£o de refer√™ncia para compara√ß√µes futuras.

## 2. Metodologia

1. **Carregamento dos dados**
   - `all_data_matlab.csv`: cont√©m colunas `wl`, `inputCalibration`, `targetCalibration`, `inputValidation`, `targetTest`, etc.
   - `all_data_IDRC.csv`: lista de valores de refer√™ncia (ordem de valida√ß√£o).
2. **Prepara√ß√£o dos conjuntos**
   - **Treino (calibra√ß√£o)**: linhas onde `inputCalibration` e `targetCalibration` n√£o s√£o nulos.
   - **Valida√ß√£o**: linhas indicadas pelos IDs do arquivo `all_data_IDRC.csv`. Essa parti√ß√£o usa `inputValidation` vs. refer√™ncia do IDRC.
   - **Teste**: resto dos dados com `inputTest` e `targetTest`.
3. **Ajuste do modelo**
   ```python
   from sklearn.linear_model import LinearRegression
   model = LinearRegression()
   model.fit(X_train, y_train)
   ```
4. **C√°lculo das m√©tricas (baseline)**
   - **MSE** (Mean Squared Error)
   - **MAE** (Mean Absolute Error)
   - **R¬≤** (coeficiente de determina√ß√£o)
5. **Gera√ß√£o de sa√≠da**
   - `baseline_results.csv`: cont√©m as m√©tricas para **valida√ß√£o** e **teste**.

---

## 3. Como executar

```bash
# Instalar depend√™ncias (incluindo scikit-learn)
pip install -r requirements.txt

# Entrar na pasta da atividade final
cd atividade_final

# Rodar o script de baseline
python baseline_mlr.py
```

O script ir√° imprimir no console e salvar em `baseline_results.csv`:

- Valores de MSE, MAE e R¬≤ para os conjuntos de **Valida√ß√£o** e **Teste**.

---

## 4. Resultados do baseline

| Conjunto    |    MSE    |    MAE    |     R¬≤     |
|-------------|-----------|-----------|------------|
| **Valida√ß√£o** | 1.09754   | 0.74191   | ‚Äì0.08798   |
| **Teste**     | 1.35652   | 0.88702   | ‚Äì0.02204   |

> **Observa√ß√£o**: R¬≤ negativo indica que a regress√£o linear simples est√° pior que uma previs√£o da m√©dia dos valores. Esse baseline √© uma linha de base para compara√ß√£o com melhorias futuras.

---

## 5. Pr√≥ximos Passos

1. **Normaliza√ß√£o/Escala** das features (`wl` e `input`).
2. **Engenharia de Features** (intera√ß√µes, polin√¥mios, an√°lise de correla√ß√£o).
3. **Modelos regularizados** (`Ridge`, `Lasso`) para evitar overfitting.
4. **Sele√ß√£o de Vari√°veis** (`SelectKBest`, `RFE`).
5. **Reavalia√ß√£o** das m√©tricas para verificar ganhos em MSE, MAE e R¬≤.

---